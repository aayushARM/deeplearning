{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import matplotlib.image as mtlimg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Find corners of Chessboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_chess_image_point_corner_pts(num_row, num_col, glob_path, is_plot=False, is_debug=False):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((num_col*num_row,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:num_row, 0:num_col].T.reshape(-1,2)\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(glob_path)\n",
    "    print (\"found \" + str(len(images)) + \" image\")\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        \n",
    "        if is_debug: print (\"Processing \" + fname, end = ', ')\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (num_row, num_col), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            if is_debug: print (\"found corner:\" + str(num_row) + \"x\" + str(num_col), end= \" ,\")\n",
    "            print (\".\", end=\" \")    \n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            if is_plot:\n",
    "                # Draw and display the corners\n",
    "                cv2.drawChessboardCorners(img, (num_row ,num_col), corners, ret)\n",
    "                cv2.imshow('img', img)\n",
    "                cv2.waitKey(500)\n",
    "\n",
    "    cv2.destroyAllWindows() \n",
    "    return objpoints, imgpoints\n",
    "    \n",
    "#def calibate_camera(glob_path, ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "glob_path = 'camera_cal/calibration*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 24 image\n",
      ". . . . . . . . . . . . . . . . . . done\n"
     ]
    }
   ],
   "source": [
    "objpoints, imgpoints = get_chess_image_point_corner_pts(9, 6, glob_path, is_plot=False, is_debug=False)\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Calibrate and UnDistort image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calibrate_camera(objpoints, imgpoints, img):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None,None)\n",
    "    cal_dict = {}\n",
    "    cal_dict['mtx'] = mtx\n",
    "    cal_dict['dist'] = dist\n",
    "    return cal_dict\n",
    "\n",
    "def un_distort_image(img, cal_dict):\n",
    "    dst = cv2.undistort(img, cal_dict['mtx'], cal_dict['dist'], None, cal_dict['mtx'])\n",
    "    return dst\n",
    "\n",
    "def get_un_distort_from_distorted_image(test_image_path, objpoints, imgpoints):\n",
    "    img = cv2.imread(test_image_path)\n",
    "    calibration_dict = calibrate_camera(objpoints, imgpoints, img)\n",
    "    img_un_dist = un_distort_image(img, calibration_dict)\n",
    "    return img, img_un_dist, calibration_dict\n",
    "    \n",
    "def plot_two_images(img1, img2, left_title=\"Left Image\", right_title=\"Right image\"):\n",
    "    f, axes = plt.subplots(1, 2, figsize=(20,10))\n",
    "    axes[0].imshow(img1, cmap='gray')\n",
    "    axes[0].set_title(left_title, fontsize=20)\n",
    "    axes[1].imshow(img2, cmap='gray')\n",
    "    axes[1].set_title(right_title, fontsize=20)    \n",
    "    \n",
    "def plot_distorted_image_un_distorted_image(image_path, objpoints, imgpoints, is_plot=False):\n",
    "    img, img_un_dist, calibration_dict = get_un_distort_from_distorted_image(image_path, objpoints, imgpoints)\n",
    "    if is_plot:\n",
    "        plot_two_images(img, img_un_dist, left_title=\"Original image\", right_title=\"Undistorted image\")\n",
    "    return img, img_un_dist, calibration_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_ = plot_distorted_image_un_distorted_image(\"camera_cal/calibration1.jpg\", objpoints, imgpoints, is_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "_  = plot_distorted_image_un_distorted_image(\"camera_cal/calibration2.jpg\", objpoints, imgpoints, is_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_ = plot_distorted_image_un_distorted_image(\"camera_cal/calibration3.jpg\", objpoints, imgpoints, is_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cal_image = cv2.imread(\"camera_cal/calibration1.jpg\")\n",
    "cal_dict = calibrate_camera(objpoints, imgpoints, cal_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Step to perform Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_perspective_transform(src, dest, undist_image):\n",
    "    M = cv2.getPerspectiveTransform(src, dest)\n",
    "    img_size = (undist_image.shape[1], undist_image.shape[0])\n",
    "    warped = cv2.warpPerspective(undist_image, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return M, warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "perspective_image_path = \"test_images/straight_lines2.jpg\"\n",
    "pesp_img = cv2.imread(perspective_image_path)\n",
    "pesp_img_rgb = cv2.cvtColor(pesp_img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1356b6710>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "persp_test_image = mtlimg.imread(perspective_image_path)\n",
    "print (persp_test_image.shape)\n",
    "plt.imshow(persp_test_image)\n",
    "plt.plot(207, 720, \"+\")\n",
    "plt.plot(1100, 720, \".\")\n",
    "plt.plot(667, 440, \".\")\n",
    "plt.plot(611, 440, \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "src_pnts = np.float32([\n",
    "  [207, 720],\n",
    "  [1100, 720],\n",
    "  [667, 440],    \n",
    "  [611, 440]\n",
    "\n",
    "])\n",
    "dst_pnts = np.float32([\n",
    "  [207, 720],\n",
    "  [1100, 720],\n",
    "  [1100, 110],    \n",
    "  [207,  110]\n",
    "])\n",
    "\n",
    "# corners = np.float32([[190,720],[589,457],[698,457],[1145,720]])\n",
    "# new_top_left=np.array([corners[0,0],0])\n",
    "# new_top_right=np.array([corners[3,0],0])\n",
    "# offset=[150,0]\n",
    "    \n",
    "img_size = (persp_test_image.shape[1], persp_test_image.shape[0])\n",
    "# src_pnts = np.float32([corners[0],corners[1],corners[2],corners[3]])\n",
    "# dst_pnts = np.float32([corners[0]+offset,new_top_left+offset,new_top_right-offset ,corners[3]-offset])    \n",
    "    \n",
    "img_un_dist= un_distort_image(persp_test_image, cal_dict)\n",
    "M, warped = get_perspective_transform(src_pnts, dst_pnts, persp_test_image)\n",
    "img_rgb = cv2.cvtColor(pesp_img, cv2.COLOR_BGR2RGB)\n",
    "warped_rgb = cv2.cvtColor(warped, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plot_two_images(img_rgb, warped_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Apply color transfor and image gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def magnitute_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to threshold an image on directon for a given range and Sobel kernel\n",
    "def direction_threshold(img, sobel_kernel=3, dir_thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= dir_thresh[0]) & (absgraddir <= dir_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mag_thres_test = magnitute_thresh(test_img, mag_thresh=(70, 230))\n",
    "plot_2_images(test_img, mag_thres_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dir_thres_test = direction_threshold(test_img, dir_thresh=(0, 2* np.pi))\n",
    "plot_2_images(test_img, dir_thres_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
